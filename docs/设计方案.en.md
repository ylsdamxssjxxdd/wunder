# wunder System Design

## 1. Goals and scope

- Build a FastAPI-based agent orchestration system that integrates LLMs, MCP, and Skills.
- Expose `/wunder` as a unified entry, accepting user id and question, streaming intermediate progress and final responses.
- Support multi-user concurrency with persistent workspaces per user id.
- Centralized configuration for LLM APIs, MCP tools, and Skills.

## 2. Requirements

### 2.1 Functional requirements

- Accept `user_id` and `question`, return streaming progress and final answer.
- Built-in toolchain: read, write, edit, search, list files, replace text, execute commands, ptc.
- Orchestrate via LLM + MCP + Skills with tool calls and workflows.
- Persistent per-user workspaces and history.
- Language switching: UI and API messages/system prompts follow selected language.

### 2.2 Non-functional requirements

- High concurrency: support multiple users and long-lived streaming connections.
- Stability: timeouts, retries, graceful degradation, observability.
- Security: workspace isolation, tool permission control.
- Maintainability: clean modules and centralized configuration.
- Startup performance: lazy init for MCP/monitor/orchestrator to reduce cold start.

## 3. Architecture

```text
Web Debug UI / Client
  |
  |  /wunder (SSE/Streaming)
  v
API Layer (FastAPI)
  |
  v
Prompt Builder
  |
  v
Orchestrator Engine
  |             |               |
  v             v               v
LLM Adapter    MCP Client       Skills Engine
  |             |               |
  +-------------+---------------+
                |
                v
            Tool Execution
           /        \
      Local Exec    Sandbox Exec
                    |
           Shared Sandbox Service

Workspace/Memory/Logs
```

## 4. API design

See `docs/API文档.en.md`.

## 5. Core modules

### 5.1 API layer

- FastAPI routing, unified `/wunder` entry.
- Lightweight ASGI entry (`app/asgi.py`) with lazy warmup.
- Connection lifecycle management, SSE streaming.
- Unified auth and validation (Pydantic), API/MCP secured by `security.api_key`.
- Routes split by domain (core/admin/workspace/user_tools), logic in `app/services` for reuse.

### 5.2 Orchestrator

- Input parsing, task planning, tool selection/execution.
- Progress events are summarized to avoid leaking internal reasoning.
- Global concurrency limit by `server.max_active_sessions`, overflow queues.
- Admin settings can update `server.max_active_sessions` at runtime and persist overrides.
- Per-user mutual exclusion via SQLite `session_locks` with TTL heartbeats.
- Max rounds by `llm.models.<name>.max_rounds` to prevent loops.
- SSE disconnect does not stop tasks; events still recorded.
- SSE overflow events stored and replayed.
- Cancellation attempts to stop LLM calls and tools.

### 5.3 Tool system

- Built-in tools (EVA style): final answer, exec commands, ptc, list/search/read/write/replace/edit files.
- Tool specs and execution are centralized in `app/tools/catalog.py` for consistency.
- Tool availability assembled by `app/tools/availability.py` for both `/wunder/tools` and prompt injection.
- Built-in tools run locally or via sandbox (commands/ptc).
- Built-in tool enable list in config/admin page; only enabled tools are injected.
- `/wunder/tools` lists built-in/MCP/knowledge/skills; prompt injection uses `tool_names`.
- MCP tools: connected via fastmcp Client, enabled tools injected; called as `server@tool`.
- Self-hosted MCP: `/wunder/mcp`, visible but disabled by default; provides `wunder@excute` and `wunder@doc2md`.
- MCP config supports import, headers/transport, cached tool specs for prompt injection.
- Skills: enabled skills inject name/description from SKILL.md; model instructed to read first.
- Knowledge tools: each base is a tool with `query/limit`.
- Knowledge bases can be enabled/disabled; disabled bases not injected.
- Custom tools: user MCP/skills/knowledge with `user_id@` prefix.
- Shared tools: shared user tools appear in tool list with `owner_id@` prefix.
- Personal knowledge base lives under `data/user_tools/{user_id}/knowledge/<base>`.
- Knowledge upload currently accepts Markdown only; convert via `/wunder/doc2md/convert` first.
- Extra prompt appended to system prompt for the user.

### 5.4 LLM adapter

- Unified `LLMClient` interface.
- Multiple model configs and default selection.
- Timeout, retries, rate limiting, fallback; exponential backoff on failures.
- Reasoning content is preserved when available.
- Streaming returns usage when possible (`stream_include_usage`).
- Global HTTP client pool for LLM/MCP/sandbox calls.

### 5.5 Workspace & Memory

- Per-user workspace:
  - `workspaces/{user_id}/` (prompt uses `/workspaces/{user_id}/` as the working directory)
- SQLite persistence:
  - `data/wunder.db` (history, tool logs, artifacts, monitor, logs, locks, SSE overflow)
- Admin override config:
  - `data/config/wunder.override.yaml`
- Legacy `data/historys/` kept for migration.
- `data/user_tools/{user_id}/config.json`: custom tools config and extra prompt.
- `data/user_tools/{user_id}/skills/`: user skills.
- `data/user_tools/{user_id}/knowledge/`: user knowledge roots.
- Context compaction triggered by `history_compaction_ratio` and safe budget; structured summary + artifact index.
- Workspace tree cache with versioning and dirty flags.
- Artifacts index records file changes/commands/outputs for prompt injection.
- Skills: usage protocol and SKILL.md path list injected to prompt.
- Reference EVA tool protocol.

### 5.6 Prompt & agent design

- Prompts split into system/tool/engineer blocks, assembled by Prompt Builder.
- Templates in `app/prompts` with language variants (e.g., `app/prompts/en`).
- Prompt build uses LRU cache; file reads are cached by mtime.
- System prompt preview is lightweight and skips tool executor init.
- Skill specs are cached by path mtime and enabled list.
- ToolSpec serialization is cached.
- Workspace tree cache reduces IO.
- Artifact index is injected to avoid losing key actions.
- Skills usage protocol appended when skills enabled.

### 5.7 Frontend debug console

- A simple web UI to test `/wunder` streaming and non-stream APIs.
- Static assets served at `/` by default (`/wunder/web` kept for compatibility).
- System intro panel embeds `/wunder/ppt` (and `/wunder/ppt-en`).
- UI includes user_id/session_id/question, event log, prompt viewer.
- MCP/Skills/Built-in tools/Knowledge management panels.
- Model config panel with multiple configs and default selection.
- Debug panel supports model selection.
- Prompt page includes custom/shared tools and extra prompt.
- Skills upload and delete for EVA_SKILLS.
- Knowledge base CRUD and Markdown file editing.
- Workspace explorer with tree view, search, batch ops, drag & drop.
- Attachment upload for files/images with doc2md parsing.
- Language selector in settings; requests carry `X-Wunder-Language`.

### 5.8 Sandbox service

- Shared sandbox service runs in a separate container but shares the same image and workspace mounts.
- Exposes `/sandboxes/execute_tool` for command/ptc execution.
- The sandbox mounts app code (readonly), user workspace (rw), EVA_SKILLS (readonly).
- At runtime, `WUNDER_SANDBOX_ENDPOINT` is preferred and the client falls back between common `sandbox`/`127.0.0.1` endpoints to avoid IP issues in intranet docker compose deployments (no need to publish port 9001).

## 6. Suggested directory structure

```text
wunder/
app/
    asgi.py
    api/
    services/
    core/
    mcp/
    knowledge/
    orchestrator/
    llm/
    monitor/
    tools/
    skills/
    memory/
    storage/
    schemas/
    prompts/
  web/
    index.html
    app.js
    app.config.js
    modules/
      elements.js
      state.js
      utils.js
      log.js
      api.js
      tool-detail.js
      workspace.js
      tools.js
      prompt.js
      debug.js
      monitor.js
      mcp.js
      builtin.js
      skills.js
      llm.js
  config/
    wunder.yaml
  workspaces/
  data/
    knowledge/
    user_tools/
    wunder.db
    historys/
  docs/
    设计方案.md
    API文档.md
    功能迭代.md
    ppt/
      slides/
  scripts/
    update_feature_log.py
  requirements.txt
```

## 7. Config specification (base + override)

Base config: `config/wunder.yaml` (override with `WUNDER_CONFIG_PATH`).
Admin override: `data/config/wunder.override.yaml` (override with `WUNDER_CONFIG_OVERRIDE_PATH`).

```yaml
server:
  host: 0.0.0.0
  port: 8000
  stream_chunk_size: 1024
  max_active_sessions: 30

i18n:
  default_language: zh-CN
  supported_languages:
    - zh-CN
    - en-US
  aliases:
    zh: zh-CN
    zh-cn: zh-CN
    zh-hans: zh-CN
    zh-hans-cn: zh-CN
    en: en-US
    en-us: en-US

llm:
  default: main
  models:
    main:
      enable: true
      provider: openai_compatible
      base_url: https://api.example.com
      api_key: ${WUNDER_LLM_API_KEY}
      model: gpt-4.1
      temperature: 0.7
      timeout_s: 60
      retry: 2
      max_rounds: 10
      max_context: 128000
      max_output: 4096
      support_vision: false
      stream: false
      stream_include_usage: true
      history_compaction_ratio: 0.8
      history_compaction_reset: zero
      stop:
        - </tool_call>
      mock_if_unconfigured: true

# provider presets (OpenAI compatible)
# - openai_compatible: custom OpenAI-compatible endpoint, base_url is required
# - openai/openrouter/siliconflow/deepseek/moonshot/qwen/groq/mistral/together/ollama/lmstudio: base_url can be omitted and will be filled automatically

mcp:
  timeout_s: 120
  servers:
    - name: wunder
      display_name: Wunder Agent
      endpoint: ${WUNDER_MCP_ENDPOINT:-http://127.0.0.1:18000/wunder/mcp}
      transport: streamable-http
      enabled: false
      allow_tools: []
      tool_specs:
        - name: excute
          description: Execute a wunder task and return the final response
          input_schema:
            type: object
            properties:
              task:
                type: string
                description: Task description
            required:
              - task
        - name: doc2md
          description: Convert document to Markdown
          input_schema:
            type: object
            properties:
              source_url:
                type: string
                description: Download URL (must include extension)
            required:
              - source_url
    - name: WebSearch
      display_name: Aliyun BaiLian WebSearch
      endpoint: https://dashscope.aliyuncs.com/api/v1/mcps/WebSearch/sse
      transport: sse
      description: Web search based on Qwen retrieval models
      headers:
        Authorization: Bearer ${DASHSCOPE_API_KEY}
      allow_tools: []
      enabled: true

skills:
  paths:
    - ./skills
    - ./EVA_SKILLS
  enabled: ["skill_a", "skill_b"]

tools:
  builtin:
    enabled:
      - 最终回复
      - 执行命令
      - ptc
      - 列出文件
      - 搜索内容
      - 读取文件
      - 写入文件
      - 替换文本
      - 编辑文件

knowledge:
  bases:
    - name: Company Policy KB
      description: Policies and procedures
      root: ./knowledge/plan
      enabled: true

workspace:
  root: ./workspaces
  max_history_items: 200
  retention_days: 30

storage:
  db_path: ./data/wunder.db

security:
  api_key: ylsdamxssjxxdd
  allow_commands: ["*"]
  allow_paths: ["./EVA_SKILLS", "./skills"]
  deny_globs: ["**/.git/**"]

sandbox:
  mode: local
  endpoint: http://sandbox:9001
  image: wunder:20250105-x86
  container_root: /workspaces
  network: bridge
  readonly_rootfs: true
  idle_ttl_s: 0
  timeout_s: 120
  resources:
    cpu: 1.0
    memory_mb: 2048
    pids: 256

observability:
  log_level: INFO
  monitor_event_limit: 500
  monitor_payload_max_chars: 0
  monitor_drop_event_types:
    - llm_output_delta
```

Notes:
- `workspace.max_history_items` <= 0 means unlimited.
- `workspace.retention_days` <= 0 disables cleanup.
- `observability.monitor_event_limit` <= 0 means no pruning.
- `observability.monitor_payload_max_chars` <= 0 disables truncation.

## 8. Persistence & cleanup

- Chat history stored in SQLite `data/wunder.db` (`chat_history`).
- Tool logs stored in `tool_logs` for replay.
- Monitor sessions stored in `monitor_sessions`.
- System logs stored in `system_logs`.
- System prompt stored as a system message for auditing.
- Long-term memory stored in `memory_settings`/`memory_records` (max 30 per user).
- Cleanup by `retention_days` if > 0.

## 9. Security & access control

- API/MCP requests require `security.api_key`.
- Workspace isolation and path traversal protection.
- Command allowlist; `allow_commands` can be `*` to allow all.
- File tools limited to workspace unless paths are allowlisted.
- Strict parameter validation.

## 10. Reliability & observability

- Unified error codes and structured exceptions.
- Logs and metrics for requests/tools/models.
- Monitor events are truncated and filtered to control memory/storage.
- Streaming supports reconnects with `llm_stream_retry` events.
