# 向量知识库实现方案

## 1. 现状审查
- 字面知识库：`src/services/knowledge.rs` 解析 Markdown，`src/services/tools.rs` 作为知识库工具调用并通过 LLM 进行候选筛选。
- 管理/用户配置：`/wunder/admin/knowledge*` 与 `/wunder/user_tools/knowledge*` 以文件为中心做增删改查，doc2md 上传会转为 Markdown 并触发刷新。
- 用户知识库存储：当前根目录固定在 `data/user_tools/<user_id>/knowledge`（见 `src/services/user_tools.rs`），前端提示亦与此一致。
- 模型配置：管理端仅支持 LLM 模型（`web/modules/llm.js`），`Config` 无嵌入模型类型区分。
- 向量能力：配置里已有 `vector_knowledge`（RAGFlow）与 `kb_query` MCP，但本方案不使用，Rust 主流程仍未接入向量检索。

结论：可以复用“知识库即工具”的框架、doc2md 解析链路与用户知识库管理 UI，但需要引入嵌入模型类型、向量库、索引与检索链路。

## 2. 目标与范围
- 在字面知识库基础上新增“向量知识库”类型，并与字面库并行展示/管理。
- 向量知识库使用 Weaviate 作为向量数据库；embedding 模型由管理端模型配置页面统一管理。
- 每条向量知识必须绑定嵌入模型标识，查询时严格匹配该模型，避免混用。
- 向量知识库文档与切片元数据统一存储在数据库（Postgres/SQLite），不再落盘到 `vector_knowledge/` 目录，root 仅保留逻辑标识。
- 支持用户上传文件 → doc2md 解析 → 字符切片 → 生成向量 → 可视化切片与原文。
- 向量知识库启用后，以工具形式挂载到系统提示词（与字面库一致）。

## 3. 方案设计
### 3.1 模型配置扩展（区分 LLM/Embedding）
- `LlmModelConfig` 新增字段：`model_type: llm|embedding`（默认 llm，兼容旧配置）。
- 嵌入模型可沿用 provider/base_url/api_key/model，但隐藏/忽略 chat 专有字段（temperature、max_rounds、tool_call_mode 等）。
- 供知识库选择嵌入模型时只列出 `model_type=embedding` 的模型。
- 嵌入模型维度与限额不对用户暴露、不做用户侧限额；如需校验可在服务端自动探测并内部记录 `embedding_signature`。

### 3.2 Weaviate 接入
- docker compose 新增 `weaviate` 服务，禁用内置向量化模块（`DEFAULT_VECTORIZER_MODULE=none`），启用持久化卷。
- 连接配置建议放在 `vector_store.weaviate`：
  - `url`、`api_key`、`timeout_s`、`batch_size`、`tenant_mode`（按 user_id 或 base_id）。
- Rust 侧新增 `vector_store` client（reqwest 直连 REST），避免引入重型 SDK。

### 3.3 数据模型与元数据
建议分层：
- **数据库（Postgres/SQLite）**：存储文档原文、切片元数据与索引字段，避免文件落盘。
  - `vector_documents`：doc_id/owner_id/base_name/doc_name/embedding_model/chunk_size/chunk_overlap/chunk_count/status/created_at/updated_at/content/chunks_json
- **向量数据（Weaviate）**：
  - Class: `KnowledgeChunk`
  - properties: `owner_id/base_id/doc_id/doc_name/chunk_index/start/end/content/content_hash/embedding_model/created_at`
  - vector: external embeddings（vectorizer none）
- 所有记录均带 `embedding_model` 字段；查询时额外 filter，避免模型混用。

### 3.4 解析、切片与索引流程
1. 上传文件 → 调用 doc2md 解析得到 Markdown 文本。
2. 文本清理（保留换行）→ 以“字符长度”为主切片（默认 800-1200 字符，overlap 100）。
3. 生成 `doc_id` 与 `chunk_id`，保存文档与切片元数据（初始状态为 `pending`，不自动向量化）。
4. 管理端可对切片进行编辑/删除，并按需触发批量嵌入或整库重建嵌入，将向量写入 Weaviate。
5. 嵌入完成后更新切片状态与文档状态（全量嵌入后标记 `ready`），供 UI 展示与检索判断。

### 3.5 检索与工具挂载
- 向量知识库工具与字面库共用 `query/limit/keywords` 入参；keywords 支持数组，向量检索会逐个关键词执行；真正检索配置（top_k、score_threshold）写在 base 配置内。
- 工具执行时：
  1. 读取 base 的 `embedding_model`；
  2. 对 query 或关键词列表批量生成 embedding；
  3. Weaviate 过滤 base_id + owner_id + embedding_model，返回 top_k；
  4. 结果写回工具输出（包含 `document/section/chunk_index/score/embedding_model`）。
- 仅对已嵌入切片参与检索，未嵌入切片不会进入候选结果。
- `knowledge_request` 事件增加 `embedding_model` 与 `vector` 标识，便于调试。
- token 统计仍以最终注入上下文的内容为准，不统计 embedding 调用消耗。

### 3.6 可视化与可控性
- 文档视图：原文通过弹窗查看，避免挤占切片区域。
- 切片视图：按 chunk_index 展示列表与状态，支持多选。
- 切片操作：双击切片编辑内容，批量嵌入/删除切片。
- 管理操作：重建嵌入（全库）、文档删除（列表悬浮操作）。
- 评估辅助：提供向量知识库测试入口，左右分栏展示问题与召回结果。
- 状态：文档 `pending/ready`；切片 `pending/embedded/deleted`。

### 3.7 性能与稳定性
- 嵌入批处理（batch_size），并发上限可配。
- Weaviate 使用持久化卷 + 备份策略（后续可接入 S3 备份）。
- 重要路径避免跨进程阻塞，索引任务可移入后台队列（后续阶段）。

## 4. API 规划（在现有知识库 API 上扩展）
- `GET/POST /wunder/admin/knowledge` 与 `/wunder/user_tools/knowledge`
  - base 增加字段：`type`、`embedding_model`、`chunk_size`、`chunk_overlap`、`top_k`、`score_threshold`
  - `type=vector` 时要求 `embedding_model`，root 保留 `vector_knowledge/...` 逻辑标识，向量文档/切片存储在数据库中
- `POST /wunder/*/knowledge/upload`
  - 字面库：保持原行为
- 向量库：doc2md → 切片（pending），返回 `doc_id/chunk_count/status`，嵌入需通过 chunk/embed 或 reindex 触发
- 新增：
  - `GET /wunder/*/knowledge/docs?base=`：返回文档列表、状态、chunk_count
  - `GET /wunder/*/knowledge/chunks?base=&doc_id=`：返回 chunk 列表（含 start/end/preview）
  - `POST /wunder/*/knowledge/reindex`：按 base/doc 重建索引
  - `POST /wunder/admin/knowledge/test`：知识库测试（向量返回召回结果，字面返回模型输出 + 命中文档）
- 兼容已有接口：不传 type 默认 `literal`。

## 5. 前端改造
### 5.1 管理端（web）
- LLM 配置页新增“模型类型”选择；嵌入模型隐藏无效字段。
- 知识库管理页：base 配置新增 type + embedding_model + chunk 配置。
- 向量库文档区：显示 doc 状态、chunk 数量；切片支持多选与批量嵌入/删除，原文通过弹窗查看，提供测试入口。

### 5.2 用户侧（frontend）
- 用户知识库新增类型选择（字面/向量），向量库需选择嵌入模型。
- 向量库文档页支持上传、查看原文、切片列表与高亮预览。
- 主题保持浅/深两套一致性，注意配色对比。

## 6. 部署与运维
- docker compose 新增 weaviate 服务与持久化卷。
- 生产配置：显式设置 weaviate URL、API Key、资源限制。
- 长期运行：监控 Weaviate 磁盘占用、定期备份、提供重建脚本。

## 7. 实施步骤（MVP→增强）
1. 模型配置增加 `model_type` + embeddings 调用。
2. Weaviate 接入 + vector_store client。
3. 向量知识库数据结构与 API 扩展。
4. 前端支持向量库配置与可视化。
5. 工具挂载与检索回传，补充监控事件与日志。
6. 文档更新与最小测试（doc2md + embedding + weaviate）。
